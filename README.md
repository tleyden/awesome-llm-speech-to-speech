
# Awesome LLM Speech-to-Speech models and frameworks

Everything in the list:

* Integrates with an LLM.  Either as a separate module, or has the LLM baked-in as part of a speech-to-speech model 
* Supports speech-to-speech, not just speech-to-text or text-to-speech

If you know of any corrections or missing entries, help curate the list by [opening a PR](https://github.com/tleyden/awesome-llm-speech-to-speech/pulls).

### Local 

* Libraries, frameworks, or models that can be run locally

| Project                                                                                                              | Open Source             | e2e or cascading model                                                          | Supported LLMs                                | Supports tool calling                 | Supported Platforms | Requires GPU + CUDA         | Supports barge-in | Demo                                                         | Supports voice cloning                | Supported languages        | Cost                                          | Includes API Server                                                                          | Additional Cmments                    |
| :----------------------------------------------------------------------------------------------------------------------- | :---------------------- | ------------------------------------------------------------------------------- | --------------------------------------------- | ------------------------------------- | --------------------------------- | --------------------------- | ----------------- | ------------------------------------------------------------ | ------------------------------------- | -------------------------- | --------------------------------------------- | -------------------------------------------------------------------------------------------- | ------------------------------------- |
| [Unmute.sh](https://github.com/kyutai-labs/unmute)                                                                       | Yes                     | Cascading                                                                       | Any local LLM                                 | Not yet, but looking for contributors | Linux only                        | Yes                         | Yes               | [Interactive Demo](https://unmute.sh/)                       | Yes                                   | EN, FR                     | Free                                          | Yes, mostly compatible with OpenAI Realtime Speech                                           | From Kyutai, makers of Moshi          |
| [Speaches](https://github.com/speaches-ai/speaches)                                                                     | Yes (MIT)               | Cascading                                                                       | Any OpenAI-compatible LLM (local or remote)   | Yes (via OpenAI-compatible API)       | Windows/Linux/Mac/Docker          | Optional (GPU recommended)       | Yes               | [Recorded Demo](https://github.com/speaches-ai/speaches)    | Yes (via Kokoro and Piper)           | EN, FR, ES, ZH, JA, KO       | Free / Self-hosted                              | Yes (OpenAI-compatible API endpoints for /v1/audio and /v1/chat)                            | “Ollama for Speech.”  Supports realtime transcription, translation, and TTS via Docker.       |
| [Ultravox (Fixie)](https://github.com/fixie-ai/ultravox)                                                                 | Yes (open-weight / MIT) | Hybrid: audio-native LLM with ASR, separate TTS | Llama/Mistral/Gemma backbones                 | Yes, via underlying LLM<br>           | Windows/Linux                     | Yes                         | Yes               | [Interactive Demo](https://demo.ultravox.ai/)                | N/A (it’s text-out; use your TTS)<br> | EN                         | Free to use model, hosted commercial offering | Only in hosted commercial offering                                                           |                                       |
| [RealtimeVoiceChat](https://github.com/KoljaB/RealtimeVoiceChat)                                                         | Yes (MIT)               | Cascading                                                                       | Pluggable LLM, including remote APIs          | Probably via underlying LLM           | Linux recommended, Windows maybe  | Yes                         | Yes               | [Recorded Demo](https://github.com/KoljaB/RealtimeVoiceChat) | Yes, via pluggable TTS engines        | EN, what else?             | Free                                          | Web Audio API (websocket based)                                                              | Author put it on hold for now         |
| [Vocalis](https://github.com/Lex-au/Vocalis)                                                                             | Yes (Apache 2)          | Cascading                                                                       | Includes fine tuned Meta LLaMA 3 8B Instruct  | Probably via underlying LLM           | Windows/Linux/Mac                | No                          | Yes               | [Recorded Demo](https://www.youtube.com/watch?v=2slWwsHTNIA) | Yes, via pluggable TTS engines        | ?                          | Free                                          | It's a bit unclear, filed [issue with question](https://github.com/Lex-au/Vocalis/issues/12) | Runs on Apple Silicon without a GPU!  Supports whisper.cpp, llama.cpp, and TTS engine supports Apple MPS  |
| [LFM2](https://www.liquid.ai/blog/liquid-foundation-models-v2-our-second-series-of-generative-ai-models?ref=producthunt) | Yes                     | E2E                                                                             | E2E model, LLM built-in                       | Yes                                   | Windows/Linux                     | Yes                         | ?                 | [Recorded Demo](https://www.youtube.com/watch?v=1eGMxkffBC8) | ?                                     | EN, JA, AR, KO, ES, FR, DE | Free                                          | No                                                                                           | From Liquid AI.  Starts at 1.5B model |
| [SimpleVoiceChat](https://github.com/thiswillbeyourgithub/simple_voice_chat)                                             | Yes                     | Cascading                                                                       | Pluggable LLM                                 | Probably via underlying LLM           | Windows/Linux/Mac                 | ?                           | ?                 | No Demo                                                      | Yes, via pluggable TTS engines        | EN, what else?             | Free with classic backend                     | No                                                                                           | Vibe coded, sits on top of fastrtc    |
| [Mini-omni2](https://github.com/gpt-omni/mini-omni2)                                                                     | Yes (MIT)               | E2E                                                                             | E2E model, LLM built-in (Qwen2)               | ?                                     | ?                                 | ?                           | ?                 | [Recorded Demo](https://github.com/gpt-omni/mini-omni2)      | ?                                     | ?                          | Free                                          | No                                                                                           |                                       |
| [Qwen2.5-Omni](https://github.com/QwenLM/Qwen2.5-Omni)                                                                   | Yes                     | E2E                                                                             | E2E model, LLM built-in (Qwen)                | Unknown - not mentioned               | Windows/Linux                     | Yes                         | Yes               | [Interactive Demo](https://chat.qwen.ai/)                    | ?                                     | EN, CN, what else?         | Free                                          | Unclear.  Maybe supports OpenAI realtime speech api, plugs into vllm                         |                                       |
| [MiniCPM-o 2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)                                                            | Yes                     | E2E                                                                             | E2E model, LLM built-in                       | Unknown - not mentioned               | Windows/Linux                     | Yes                         | ?                 | Demo Offline                                                 | ?                                     | EN, CN, what else?         | Free                                          | Just a model.  Relies on other tools.                                                        |                                       |
| [Pipecat](https://github.com/pipecat-ai/pipecat)                                                                         | Yes                     | Cascading                                                                       | Pluggable LLM, ASR, and TTS                   | Yes                                   | Windows/Linux/Mac/iOS/Android     | No                          | Yes               | ?                                                            | Yes via TTS engines                   | ?                          | Free unless pairing with daily.co platform    | No, but mentions it can be used with FastAPI                                                 | Unclear on how to fully self-host it  |
| [voicechat2](https://github.com/lhl/voicechat2)                                                                          | Yes                     | Cascading                                                                       | Pluggable LLM, (any openai compatible server) | Probably, via LLM                     | Linux                             | Yes                         | No                | [Recorded Demo](https://github.com/lhl/voicechat2)           | Yes via TTS engine                    | EN, what else?             | Free                                          | Via bespoke websocket                                                                        |                                       |
| [HuggingFace SpeechToSpeech](https://github.com/huggingface/speech-to-speech)                                            | Yes                     | Cascading                                                                       | Pluggable LLM (flexible)                      | Probably, via LLM                     | Mac/Windows/Linux                 | CUDA with fallback for Macs | ?                 | None                                                         | Yes via TTS engine                    | EN, FR, ES, ZH, JA, KO     | Free                                          | No                                                                                           |                                       |
| [Sauropod](https://github.com/sauropod-io/sauropod)                                                                      | Yes                     | Cascading                                                                       | ?                                             | ?                                     | ?                                 | ?                           | ?                 | ?                                                            | ?                                     | ?                          | Free                                          | OpenAI realtime speech compatible                                                            | Author put it on hold for now         |
| [GLaDOS](https://github.com/dnhkng/GLaDOS)                                                                             | Yes (MIT)               | Cascading (ASR + LLM + TTS)                                                     | Ollama, OpenAI, or any compatible local LLM   | Yes                                   | Windows/Linux/Mac/SBC (RK3588)   | Optional (CUDA/ROCm/DirectML)    | Yes               | [Demo Video](https://github.com/dnhkng/GLaDOS)             | Yes (via Kokoro voices)              | EN (multiple accents)        | Free / Self-hosted                              | Yes (OpenAI-compatible TTS API server via Docker)                                            | Real-life Portal-style AI.  Optimized for <600 ms latency, runs even on 8 GB SBCs.           |

There are a few more details on [this r/LocalLlama thread](https://www.reddit.com/r/LocalLLaMA/comments/1nxqabe/awesome_local_llm_speechtospeech_models_frameworks/) 
